# Individual Assignment 4: Tools for Production ML Systems

(17-445/17-645 Machine Learning in Production; 11-695 AI Engineering)

## Overview

In this assignment, you will have a chance to explore modern tools that are useful for building AI-enabled systems, many of them marketed as MLOps tools. You will try them in the context of the movie streaming scenario and write a blog post about them.

Learning goals:
* Explore the ecosystem of software engineering tools for production ML systems
* Explain to other stakeholders the purpose of a tool

## Tasks

This assignment is very open-ended and you can customize it to your interests.

Pick an aspect of building production machine learning systems that you find interesting (e.g., requirements, testing in production, data quality, deployment, operations) and look for a tool that supports this task. Try the tool in the context of the movie streaming example and write a blog post about the tool and your experience. 

Blog posts can come in different forms. We recommend one of the following:

* A blog post introducing a tool to a wider audience with an example or mini-tutorial.
* A blog post comparing multiple related tools on an example.
* A blog post showing how multiple tools complement each other.

You must pick a tool or tool combination **that you are not yet familiar with** and that has not been discussed by students in the last semester. You might want to explore tools that might help with your team project. Each student/team **must pick a different tool** or tool combination; claim the tool of your choice in the Google Spreadsheet linked from Canvas. Within 3 days after the deadline, read at least two other blog posts written by other students this semester and comment on them.

## Guidance and hints

**Picking a tool:** Claim the tool of your choice early so that you do not waste effort exploring a tool that is then claimed by somebody else. First come first serve. Please only claim one tool at any time, but you may change what tool you claim if your first choice does not turn out to be interesting or usable.

Pick a tool that you have not used before. Maybe there are tools that you have read about and are curious to explore. Maybe there are tools that improve past or future aspects of the team project, such as continuous integration, telemetry collection, containerization, A/B testing, or monitoring.

The following tools were discussed (individually) in previous semesters: [Aequitas](https://medium.com/@emehrotr/know-if-your-ml-model-is-the-champion-of-justice-using-aequitas-c78691c76c37), [Aim](https://medium.com/@vennylaras/tracking-experiments-with-aim-649140a7e4e5), [Algorithmia](https://lvandenb.medium.com/a-gentle-introduction-to-algorithmia-397669d3cd9e), [Amazon ECS](https://medium.com/@tuntunsara/practice-of-deploying-movie-recommendation-system-with-amazon-ecs-1f82a53d35e1), [Amazon Elastic MapReduce](https://sreenidhi-sundaram.medium.com/amazon-elastic-map-reduce-emr-to-scale-machine-learning-systems-5fc38be5ecd2), [Amazon Sagemaker](https://medium.com/@jackyzou1997/a-gentle-introduction-to-aws-sagemaker-ml-ai-on-the-cloud-de8dd0191818), [Amazon Sagemaker](https://medium.com/@u1singh/aws-sagemaker-for-automating-machine-learning-and-data-science-projects-19c5b5639b31), [Apache Airflow](https://medium.com/balancing-lines/automating-data-pipeline-using-apache-airflow-444e695181e9), [Apache Airflow](https://medium.com/@sparveen/maintaining-ml-models-in-production-using-airflow-and-mlflow-5726657c4e3a), [Apache Beam](https://medium.com/@xiandax/recommendation-system-with-apache-beam-as-the-streaming-data-parallel-processing-pipeline-d4823364e5d2), [Apache Flink](https://medium.com/@jundaa/a-quick-introduction-to-apache-flink-fc15ceada23), [Apache Flink](https://medium.com/@priyankbhandia_24919/apache-flink-for-data-enrichment-6118d48de04), [Apache Flume](https://wenfeiy.medium.com/a-gentle-introduction-toapache-flume-1ce715475129), [Apache Hadoop](https://medium.com/@sanshang/first-try-on-apache-hadoop-fe24aee66665), [Apache Spark](https://medium.com/@abellamk/apache-spark-with-pyspark-a-step-by-step-approach-2448a1216cd9), [Apache Storm](https://medium.com/@imarod/apache-storm-4f6cb788f240), [Aporia](https://www.youtube.com/watch?v=_GN8-LTqp2g), [ArangoDB](https://medium.com/@shiyuluu/arangodb-for-movie-recommendation-1b04832e811d), [Artillery](https://medium.com/@ankits2/load-testing-apis-with-artillery-io-cbf94c3cdaf1), [Assertible](https://medium.com/@rnakashi_18747/automated-api-testing-with-assertible-d96c42abb4bf), [Auto-Surprise](https://wangxingchen2930.medium.com/auto-surprise-automates-algorithm-and-hyperparameter-tuning-ee8f01b9f354), [AutoGluon](https://medium.com/@xiangyu_y/autogluon-easy-to-use-and-high-performing-automl-40d7408ba8b6), [AWS Cloudwatch](https://medium.com/@ayushgau/amazon-cloudwatch-648948005eb), [AWS DocumentDB](https://youtu.be/S4fBuj1HeAg), [AWS Glue](https://medium.com/@alexfungshunhang/aws-glue-in-ml-system-data-pipeline-b4385e9f2960), [Azure Functions](https://medium.com/@aadarshpratik1/deploying-models-using-azure-functions-a-tutorial-733f44379a72), [Azure ML](https://medium.com/@izad.aliakbar/azure-ml-dream-of-seasoned-data-scientists-6069c113a1c3), [Azure ML](https://qidiyang.medium.com/azure-ml-studio-movie-recommendation-using-azure-machine-learning-studio-with-matchbox-8ef535df1162), [Azure Pipelines](https://medium.com/@skovvuri_29859/continuous-deployment-with-azure-pipelines-on-azure-kubernetes-service-4a6536fe8ede), [Bamboolib](https://medium.com/@mehakm_26235/bamboolib-pandas-without-code-for-data-science-46d1b9f9cb41), [BentoML](https://medium.com/@maahin_beri/using-bentoml-to-serve-scikit-models-10f54c29dfc9), [BigDL and Streamlit](https://medium.com/@mlprodhw3/bigdl-movie-recommendation-system-3ac04d0e65cb), [BigQueryML](https://medium.com/@nzehra/bigquery-ml-for-building-and-creating-models-f38d0a748e7e), [Bodywork](https://medium.com/@mmangipu/deploying-ml-models-using-bodywork-4fa6fc4343d2), [Brooklin](https://medium.com/@stefanm_58348/brooklin-linkedins-open-source-service-for-data-streaming-7788e09a1173), [ClearML](https://youtu.be/jlLTG4jUAhI), [CML](https://medium.com/@karthik.vaithyanathan/using-continuous-machine-learning-to-run-your-ml-pipeline-eeeeacad69a3), [Comet.ml](https://medium.com/@noelchen90/using-comet-ml-in-movie-recommendation-scenario-23f012c52c04), [Core ML and Core ML Tools](https://medium.com/@dain0605/core-ml-deploy-your-model-on-device-81178469ee89), [Cortex](https://medium.com/@nsgupta.vivek/model-deployment-automation-with-cortex-45c48aaed063), [Cronitor](https://medium.com/@arshin/creating-managing-model-pipelines-with-cronitor-e4da52f40fe0), [d6tflow](https://medium.com/@dhanrajkotian12/save-time-and-efforts-deploying-ml-model-with-d6tflow-d7209605b28e), [Dagster](https://medium.com/@lyuyang.hu/dagster-how-to-cronjob-like-an-mle-c036d657fce), [Dask](https://hongkaij.medium.com/a-general-introduction-of-dask-7cf05e81398), [Data Versioning Control](https://medium.com/@khaninudomchoksakul/data-versioning-control-with-a-movie-recommender-dataset-d5dec796ff49), [Databricks with mlflow](https://medium.com/@hoikitf/databricks-with-mlflow-easy-to-use-for-implementing-end-to-end-data-science-pipeline-8d5ff267f00), [Databricks](https://sg-ecust.medium.com/databricks-data-engineering-on-the-cloud-daef343cfbf1), [DataDog](https://medium.com/@fkd_98787/datadog-monitoring-web-services-ef4404c22b06), [DataPrep](https://medium.com/@shreyash.rawat/dataprep-understanding-the-story-behind-the-data-886b6c100358), [DataRobot](https://lnatraj.medium.com/data-robot-5a0efa279d48), [deepchecks](https://medium.com/@scns.tools/how-deep-are-your-checks-59bac4d5688e), [DVC](https://medium.com/@nwest_7200/a-brief-introduction-to-data-version-control-dvc-82ec5ee76c2b), [DynaBench](https://medium.com/@haris.widjaja/dynabench-3705ef39ac76), [Elasticsearch](https://deokhk.github.io/2022/03/14/Elasticsearch.html), [Elasticsearch](https://medium.com/@anindits/elastic-search-for-ml-product-2d6b92a8473f), [Evidently](https://medium.com/@lzhangbq/evidently-evaluation-and-monitoring-tool-for-machine-learning-601c1d23049e), [FACETS](https://medium.com/@yanglq08/facets-data-visualization-tool-for-ml-datasets-68c5ccf60680), [FastAPI](https://medium.com/@yashgovilkar14/transform-your-machine-learning-model-into-a-full-stack-app-with-fastapi-and-streamlit-af90730d96de), [Github Actions](https://medium.com/@shrutina/introduction-to-github-actions-be76846b0bd9), [Google Cloud AutoML](https://docherpap.medium.com/build-your-machine-learning-model-in-minutes-with-automl-eb5c5f68d4fa), [Grafana](https://zexuannotes.com/using-grafana-prometheus-and-postgresql/), [Great Expectations](http://wordpress.com/2020/10/29/what-to-expect-with-great-expectations/), [Guild AI ](https://medium.com/@sanjanakandi/why-you-should-use-guildai-for-your-next-machine-learning-project-9b0d1af12002), [H2O](https://medium.com/@adityapaul514/end-to-end-machine-learning-with-h2o-ai-f60e8c49ff32), [Holoclean](https://medium.com/@jacob.tanenbaum/a-first-look-at-holoclean-205ca7c71369), [HuggingFace](https://www.nathanluskey.com/2022-11-08-CMU-HuggingFace/), [Hydra](https://medium.com/@haechanl/hydra-for-managing-configuration-1df16e086dab), [IBM Watson Studio](https://kingofasia.medium.com/simplifying-ai-and-machine-learning-with-ibm-watson-studio-6ddc6af0791), [interpretML](https://medium.com/@hogeony_66846/interpretml-open-source-package-for-machine-learning-a64671d9fa7), [JIRA](https://medium.com/@abuzark/parkour-making-machine-learning-agile-with-jira-d511a3e58478), [JMeter](https://medium.com/@zhuwhfrank/client-server-testing-with-jmeter-b044edff7391), [Kafka Connect](https://medium.com/@gmtang.rocks/kafka-connect-an-easier-way-to-connect-messages-with-data-stores-84e24348d216), [Katib](https://medium.com/@alanzhuyixuan/making-ml-easier-katib-bd98c44b95ba?source=friends_link&sk=525d6a584200e296fbc371df5693cf9e), [Kedro](https://medium.com/@adityasingh_10318/ml-engineering-kedro-694009eda529), [kedro](https://medium.com/@yoonseok419/kedro-an-open-source-python-framework-for-mlops-1787291d8e66), [Kedro](https://prathit-p.medium.com/kedro-software-engineering-principles-for-data-science-6eced3cc3390), [Kubeflow](https://medium.com/@rahulkishen18/running-kubeflow-pipelines-with-minikf-and-kale-on-aws-c12aef9bbc71), [Kubeflow](https://trungdcn.medium.com/kubeflow-managing-the-whole-machine-learningcycle-c9e6a6149d91), [Kubernetes](https://medium.com/@mazzottacraig/deploying-a-flask-application-with-kubernetes-8a491c220b59), [Kubernetes](https://medium.com/@tusharvatsa/captain-kubie-440fa3578fd2), [LaunchDarkly](https://martamendez.medium.com/ship-fast-and-rest-easy-feature-management-by-launchdarkly-b23752f52835), [LightFM](https://medium.com/@anudeep.sekhar/recommendation-system-in-python-968f63b2a4f4), [Lightning AI](https://tin0819tin.medium.com/make-your-ml-deployment-easy-with-lightning-ai-630a69a871d6), [Logstash](https://ccchang915.medium.com/a-gentle-introduction-to-logstash-f9b3ba032fe0), [Loki](https://medium.com/@shreyasrivastava2509/loki-prometheus-but-for-logs-d87263b9492e), [Luigi](https://jimmdd.medium.com/exploring-spotifys-luigi-to-build-etl-pipeline-97309dc01fd9), [Metaflow](https://github.com/tashee/MetaFlowProj/blob/main/Metaflow-2.pdf), [ML Workspace](https://computervision-is-fun.tistory.com/64), [Mlflow](https://medium.com/@cxie2_83485/mlflow-a-tool-for-movie-recommendation-system-d273adec311c), [MLflow](https://medium.com/@kevin.n.lu123/mlflow-managing-your-ml-pipeline-from-training-to-deployment-7e0d87df9d), [MLReef](https://medium.com/@trajanikant/mlreef-cf6cd2ea49e2), [ModelDB](https://medium.com/@songrcs/versioning-your-dataset-and-models-using-modeldb-10b0ee3873ed), [MongoDB Compass](https://medium.com/@csiga/a-brief-introduction-to-mongodb-compass-2dbc250063a0), [MongoDB](https://medium.com/@vanessaj_78011/mongodb-with-movie-data-f31fba9e160a), [MySQL](https://medium.com/@syeda.sr96/mysql-for-storing-and-telemetry-data-16e13e2e63a7), [Neo4j](https://medium.com/@mohonisc/recommendation-system-with-neo4j-graph-database-f111ff377d07?sk=83eb1f72f810fea61fbb03df94e1459e), [Neptune AI](https://medium.com/@conniefishdo07/using-neptune-ai-in-movie-recommendation-services-46244b4a03b1), [Neptune](https://medium.com/@quiet_desert_platypus_782/neptune-ai-68a7dce48880), [Netlify](https://medium.com/@a.l.andlyu/using-an-netlify-for-machine-learnig-a-b-tests-e69cd5b7faca), [Neural Network Console](https://medium.com/@joonseol/sonys-neural-network-console-for-machine-learning-8c762fbb30ea), [Neural Network Intelligence (NNI)](https://medium.com/@qiiimaoo/nni-your-plug-and-play-deep-learning-helper-298954059010), [ONNX](https://sanglee325.github.io/ml/onnx), [OpenDP](https://youtu.be/rixvwGREKkY), [OpenTelemetry](https://medium.com/@kperumal_7853/opentelemetry-for-ai-enabled-intelligent-systems-in-production-9a12f2de4081), [Optimus](https://medium.com/@bhavuks/optimus-data-processing-made-simple-8d94e6ef8778), [Optuna](https://dandaprathyusha.medium.com/optuna-in-movie-streaming-recommendation-example-9831970f11c2), [optuna](https://medium.com/@parthdm/hyperparameter-optimization-using-optuna-for-movie-review-analysis-b97e6ab8d9d9), [Orange](https://medium.com/@hkoo_17209/orange-the-easiest-color-to-implement-837b18dc2e0c), [Pachyderm](https://medium.com/@mvatsa/data-pipelines-and-versioning-with-pachyderm-7b04263f73c1), [Pandas](https://applepie617.blogspot.com/2022/03/pandas-for-data-cleaning-and-analysis.html), [PipelineX ](https://medium.com/@sijiex/software-engineering-tools-for-production-ml-systems-pipelinex-fc6216f4acd2), [Ploomber](https://medium.com/@sidhantk_56660/ml-pipelines-using-ploomber-7a69f188cf02), [Plotly Dash](https://medium.com/@rrustogi_91374/telemetry-dashboard-for-ai-applications-using-plotly-dash-9b74f7462083), [Podman](https://pub.towardsai.net/seal-the-containerized-ml-deal-with-podman-1741c5d1b870), [Polyaxon](https://medium.com/@wangxuan_46130/polyaxon-automated-pipeline-for-your-machine-learning-application-c74793281b4e), [Postman](https://medium.com/@scalablegoose/performing-end-to-end-testing-for-ml-systems-with-postman-e9fca37fb89), [Prefect](https://medium.com/@ymadhuku/orchestrating-recommendation-systems-with-prefect-4983804770e), [Prometheus](https://medium.com/@maia.raj.iyer/prometheus-for-monitoring-system-performance-metrics-9af412eeb847), [Pycaret](https://yichengb.medium.com/pycaret-low-code-machine-learning-library-that-accelerates-model-building-pipeline-295d0b9d1d3), [pydqc](https://psbbvishal.medium.com/pydqc-eda-done-in-one-command-86ca8fca791f), [PyJanitor](https://medium.com/mlearning-ai/etl-pipeline-with-pyjanitor-7834e6e6f946?sk=5840f6edd22755a49df60e9c774e3d7d), [PyTorch Lightning](https://medium.com/@ritikadhiman/pytorch-lightning-in-production-658b65451cde), [Qlik Sense](https://medium.com/@ruhip99/qlik-sense-a-modern-day-analytics-tool-ceff78f0dbd8), [Quilt](https://medium.com/@rohitgov/quilt-manage-data-like-code-ecef88b24698), [Rapid Miner](https://medium.com/@SatishCShreenivasa/rapidminer-to-build-and-visualize-data-science-workflow-fd689afd6a2b), [Ray Serve](https://medium.com/@changjiayu1997/ray-serve-for-serving-movie-recommendation-model-7501046d4c5c), [Redash](https://medium.com/@deluxe9926/overview-4dc759ba8227), [Sacred](https://medium.com/@astromsoc/sacred-your-handy-way-to-conduct-computational-research-for-machine-learning-projects-7374385363ce), [Seldon](https://medium.com/@taylorvandaff/movie-recommendations-with-seldon-from-the-perspective-of-an-ml-system-developer-b544003cba1f), [SHAP](https://medium.com/@harnoordhingra/shap-shapley-additive-explanations-efa07b47748e), [Sigopt](https://medium.com/@minwooc/sigopt-for-machine-learning-hyper-parameter-tuning-17860ffede4f), [Snorkel](https://medium.com/@FanglinChen/snorkel-for-recommendation-system-3f7c10cbdb82), [Snowflake](https://medium.com/@junhurcmu/snowflake-data-platform-as-a-service-dbdf113d8237), [Spacy](https://medium.com/@empransoumya.96/a-brief-introduction-to-spacy-and-spacy-transformers-f30f4657fec4), [SpaCy](https://medium.com/@sayali.moghe.1008/spacy-for-natural-language-processing-fe7963e5fc57), [Spark MLLib](https://medium.com/@amichell.cloud/machine-learning-with-spark-ml-f15e7e089ea0), [Spark Streaming](https://medium.com/@arpit2011/spark-streaming-95863c64d5ae), [Split.io](https://ganeshkrishna2396.medium.com/faster-deployment-and-testing-using-feature-toggling-techniques-split-io-829e3797ee69), [Splunk](https://medium.com/@bandarukanishka/using-splunk-for-data-analysis-1e945c236b3), [Tableau](https://medium.com/@jungwoo2/where-we-are-is-tabpy-5dbd79a774d4), [TensorBoard](https://clive-gomes.medium.com/visualizing-with-tensorboard-96b013f3d931), [TensorBoard](https://medium.com/@danielhhoskins/tensorboard-an-overview-and-discussion-ebc8841c09ac), [TensorFlow Lite](https://medium.com/tensorflow-lite-for-android/exploring-tensorflow-lite-for-android-aca0e0c82ba), [TorchRec](https://dhruvrnaik.medium.com/introduction-to-torchrec-870dc95fac7), [TorchServe](https://medium.com/@catherine.chang0915/serve-recommendation-models-with-torchserve-8723b1472aed), [TorchServe](https://medium.com/@mymomo119966.mm/ml-ops-with-containerized-torch-serve-movie-recommendation-as-example-b96663b4131c), [TPOT](https://medium.com/@daniel.biales/automl-taking-tpot-to-the-movies-cf7e6f67f876?sk=6737cdd9d4cf2ff3c7322ee25f80fe70), [wandb](https://medium.com/@pinnongl/weights-biases-a-tool-to-make-ml-experiments-easily-reproducible-6a155fa7a702), [Weights and Biases](https://goyalmansi.medium.com/weights-biases-developer-tools-for-machine-learning-40ff7ed53057), [Whylabs](https://medium.com/@gxchris/ml-observability-with-whylabs-54835f6ce641), [ydata-quality](https://medium.com/@zhengwez/ydata-quality-be8d99b9ca39), [ZenML](https://medium.com/@sadiyaameen/zenml-why-you-should-consider-mlops-a72ee54f5a5d).

We **recommend** to **not** discuss them again. If you want to explore one of these tools again, your blog post should provide additional value to the original one. Additional value can come from exploring additional features, discussing a different usage scenario, or discussing what has changed since the last blog post. Value can also come from comparing the tool against another or discussing the combination with another tool (no combinations have been discussed in prior semesters).

You may pick open source tools, academic prototypes, as well as commercial tools, as long as you can give the course staff access to your work. You may use the provided cloud credits for this assignment or sign up for trial versions if you like.

If there is a tool that you wanted to explore but that has already been claimed, search for competitors of that tool.

**Scope:** The tool does not need to be directly related to machine learning or use machine learning, but should be plausibly fit into a production scenario where it supports or interacts with ML components in a larger system. For example, a distributed logging system may not be designed specifically for ML applications but would be a useful foundation for collecting telemetry. Out of scope are pure data science tools that would be used by data scientists when building models (data exploration, data visualization, notebook extensions, or standard machine learning libraries) unless they can be connected to larger engineering themes. If in doubt ask the instructors whether a tool is in scope. Here are a couple of examples you could consider, but you can [find](https://neptune.ai/blog/best-mlops-tools) [many](https://www.analyticsvidhya.com/blog/2019/07/21-open-source-machine-learning-tools/) [lists](https://github.com/EthicalML/awesome-production-machine-learning) or [podcasts](https://podcast.mlops.community/) with a little searching:

* MLOps, monitoring, and deployment: e.g. Kubernetis, MLflow, Kubeflow, Apache Flume, MCenter, Prometheus, Loki, Logstash, Elasticsearch, LaunchDarkly, Split.io, MiniKube
* Pipeline automation and best practices: e.g., Kedro, Airflow, Luigi, Dask
* Data and model versioning, experimentation: e.g., dvc, ModelDB, Neptune, TensorBoard, Weights & Biases, Comet.ml
* Data programming, data cleaning, best practices: e.g. Snorkel, Holoclean, Great Expectations, pydqc
* Testing, debugging, and explainability tools: CheckList, IBM 360, IBM ART, Data Linter, Crowdsourcing Platforms, ease.ml/ci, Rainforest, JMeter, Errudite,  SHAP, RuleX, InterpretML, AdaTest
* Big data solutions: e.g., Sparks, Hadoop, Flink, Reflow, Dragster, Beam
* Learning at scale/in the cloud: e.g., Amazon SageMaker, TFX, Azure ML, Google Cloud AutoML, IBM Watson Studio, Databricks

If you search for alternatives for any of the tools above, you will typically find multiple competitors.

**Trying the tool:** For the “try the tool” part, we expect at a minimum that you install/set up the tool and use it in the context of the movie streaming scenario with some data. You can but do not need to use data from Kafka or the provided APIs or your team's production environment. We interpret "context of the movie streaming scenario" broadly: It can relate to movie recommendations, but also many other tasks that may be plausibly relevant in a movie streaming company, such as predicting movie popularity, advertising, or managing subscriptions. Feed it with some sample data from the scenario. For example, you could set up a distributed logging system and feed it with telemetry data from the team project. You may, but are not required to, fully integrate the tool with your team project or previous homework solutions. You may use your team’s virtual machine if you coordinate with the rest of your team. You can use your cloud credits if suitable.

**The blog post:** Write the blog post for a general audience of readers interested in machine learning. That is, your target audience is not other students in the class but the broader population of interested readers with some technical background (e.g., data scientists interested in building production systems, software engineers interested in machine learning, self-taught enthusiasts interested in the topic). Therefore, avoid jargon and avoid assuming too much background knowledge. Popular blogs might provide some ideas for how to write such posts, such as https://towardsdatascience.com/ or many company blogs. You may also look for inspiration in blog posts written by students in previous semesters linked above, though they may differ widely in quality.

The blog post should cover at least (1) the problem that the tool addresses, (2) a discussion how it helps illustrated with examples from the movie streaming scenario, and (3) a discussion of the strength and limitations of the tool.

We recommend that you post the blog posts publicly in a location of your choice (e.g., medium.com or GitHub pages). If you have a personal blog, feel free to post it there. If you prefer to not post the blog post publicly, post it in the Discussion section of Canvas. If you post it in a public place that does not allow comments, create a discussion post on Canvas with a link, so that other students can comment there.

If you are interested, you can also record a podcast episode or youtube video instead of writing a blogpost, covering the same requirements, but be aware that this likely requires more work. Here are two past examples: [OpenDP](https://youtu.be/rixvwGREKkY) and [Aporia](https://www.youtube.com/watch?v=_GN8-LTqp2g). Reach out to the course staff for logistics.

**The comments:** After the deadline read at least two other blog posts (you can find their links in the spreadsheet) and post comments on them. Comments can share additional experience, ask questions, or indicate insights you gained from reading the blog post. The comments are due 3 days after the assignment’s main deadline.


## Deliverable

Post the blog post, update the Google Spreadsheet with links, and submit a short PDF to Gradescope:

**(1) Post the blog post** publicly or in the discussion section on Canvas (on canvas use the prefix “Blog: ” for the title of the posting).

**(2) Update the Google Spreadsheet** linked from Canvas with the tool name and a link to your blog post by the assignment’s deadline. Within three days after the deadline add two more links to the comments you made on other blog posts to the Spreadsheet.

**(3)** Post a **PDF** to gradescope (likely just a single page, we use this primarily to track grades consistently in one place) covering:

1. **Blog post link:** Provide a link to the blog post
2. **Data, evidence, additional materials:** If not already obvious from the blogpost provide evidence that the tool was actually tried with data from the movie streaming scenario: Provide links (e.g., to GitHub) of where to find your scripts, configuration, or code, if appropriate. You may include additional screenshots, outputs, or logs if that is helpful, but there is no need to replicate information from the blog post. Provide credentials for external services, if needed. You may share with the course staff additional information that you prefer not to include in the blog post (e.g., for readability or because it is sensitive information).
2. **Differences to prior posts (optional):** If you discuss a tool that was already discussed in a previous semester, include one paragraph explaining how your blog posts differs and how it adds additional value. If you select a new tool or compare the tool with another, you can skip this section.


## Grading

The assignment is worth 100 points. We will assign credit as follows:
* [ ] 10 points: The spreadsheet is filled out correctly and we can find your blog post and comments without asking. 
* [ ] 10 points: The discussed tool or tool combination was not already claimed by a another student this semester. If the tool was already discussed in a previous semester, the blog post adds additional value that is explained in the PDF.
* [ ] 20 points: A blog post about the selected tool is posted that explains *the problem* that the tool addresses.
* [ ] 20 points: The blog post *illustrates* how the tool is useful in a production machine learning system with examples from the movie streaming scenario.
* [ ] 10 points: The blog post discusses the *strength and limitations* of the tool. 
* [ ] 10 points: The blog post is professionally written and suitable for a broad target audience of interested software engineers and data scientists, avoiding jargon and not expecting too much technical background. 
* [ ] 10 points: Evidence is provided that the tool was tried on data from the movie streaming scenario in the blog post itself and/or the PDF.
* [ ] 10 points: Two comments on other blog posts show an engagement with the content of those blog posts (i.e., beyond just “looks good” or “interesting!”).
* [ ] (optional) 3 bonus points if the blog post is posted publicly.
* [ ] (optional) 3 bonus points for doing a video or podcast instead of a blog post.

